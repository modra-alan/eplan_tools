import os
import pdb
from typing import Any, Callable
import pandas as pd
from enums import PartHeader
from classes import EplanPart, SAPPart
from api_controller import APIController
import time
import json
import logging


API_RESULTS_FILE = "outputs/api_results.json"
OUTPUT_FILE = "outputs/PartData.json"
EXCEL_PARTS_FILE = "inputs/beckhoff_parts.xlsx"


def post_request():
    df = pd.read_excel(EXCEL_PARTS_FILE, header=1)
    parts = [EplanPart(**part) for part in df.to_dict(orient="records")]  # type: ignore
    api_controller = APIController()
    response = api_controller.post_parts(
        [getattr(part, PartHeader.Type_number.name) for part in parts[:50]]
    )
    print(response.json())


def main():
    post_request()
    # logging.basicConfig(level=logging.INFO)
    # df = pd.read_excel(EXCEL_PARTS_FILE, header=1)

    # # column_map = map_columns_to_enum(df.columns)

    # with open(API_RESULTS_FILE, "r") as f:
    #     results = format_api_results(json.load(f))

    # def query_df(df: pd.DataFrame, query: str):
    #     return [
    #         EplanPart(**row)  # type: ignore
    #         for row in df[
    #             df[PartHeader.Type_number.value].str.contains(query, na=False)
    #         ].to_dict(orient="records")
    #     ]

    # matched_parts: dict[
    #     str,
    #     dict[str, list[SAPPart] | list[EplanPart] | list[tuple[EplanPart, SAPPart]]],
    # ] = {
    #     query: {
    #         "sap_parts": sap_parts,
    #         "eplan_parts": query_df(df, query),
    #         "matches": [],
    #     }
    #     for query, sap_parts in results.items()
    # }
    # for k, v in matched_parts.items():
    #     for eplan_part in v["eplan_parts"]:
    #         if not isinstance(eplan_part, EplanPart):
    #             raise TypeError(f"Expected EplanPart, got {type(eplan_part)}")
    #         for sap_part in v["sap_parts"]:
    #             if not isinstance(sap_part, SAPPart):
    #                 raise TypeError(f"Expected SAPPart, got {type(sap_part)}")
    #             eplan_part_name = str(
    #                 getattr(eplan_part, PartHeader.Type_number.name)
    #             ).strip()
    #             if any(
    #                 eplan_part_name in val
    #                 for val in [sap_part.ItemName, sap_part.FrgnName]
    #             ):
    #                 v["matches"].append((eplan_part, sap_part))  # type: ignore

    # for k, v in matched_parts.items():
    #     if not v["matches"]:
    #         continue
    #     print(f"Query:          {k}")
    #     print(f"Matches:        {v['matches']}")
    #     print(
    #         f"SAP Parts:      {[part.ItemName for part in v['sap_parts'] if isinstance(part, SAPPart)]}"
    #     )
    #     print(
    #         f"Eplan Parts:    {[getattr(part, PartHeader.Type_number.name) for part in v['eplan_parts']]}"
    #     )


def format_api_results(api_results: dict[str, Any]):
    """Formats the results from the API into a dictionary of SAPPart objects

    Args:
        api_results (dict[str, Any]): Results from the API (generated by query_api_save_results)

    Raises:
        ValueError: If the list of responses contains an unexpected response

    Returns:
        dict[str, SAPPart]: Dictionary of SAPPart objects with the query as the key
    """
    result: dict[str, list[SAPPart]] = {}
    for query, response in api_results.items():
        if "message" in response:
            continue
        elif "data" in response:
            result.update({query: [SAPPart(**part) for part in response["data"]]})
        else:
            raise ValueError(f"Unexpected response {response} for query {query}")

    return result


def query_api_save_results(df: pd.DataFrame, column_map: dict[PartHeader, int]):
    """Queries the API for parts and saves the results to API_RESULTS_FILE"""
    count = 0
    num_queries = 20
    limit = len(df)
    results = {}
    while count < limit:
        upper_bound = count + num_queries if count + num_queries < limit else limit
        logging.info(f"Getting parts {count} to {upper_bound} of {limit}")
        try:
            results.update(
                get_parts_from_api(
                    df[count:upper_bound],
                    column_map,
                )
            )
        except ConnectionError as er:
            logging.critical("Connection error, salvaging results and exiting")
            with open("outputs/salvaged_results.json", "w") as f:
                json.dump(results, f, indent=4)
            raise ConnectionError("Error connecting to API") from er
        count += num_queries
        time.sleep(0.5)

    with open(API_RESULTS_FILE, "w") as f:
        logging.info(f"Writing {len(results)} results to {API_RESULTS_FILE}")
        json.dump(results, f, indent=4)


def sort_families(input_filepath: str, output_filepath: str):
    with open(input_filepath, "r") as f:
        data = json.load(f)
    strong_matches = {}
    weak_matches = {}
    matched_parts = {}
    for family, part_dict in data.items():
        for part_num in part_dict["part_numbers"]:
            for match in part_dict["matches"]:
                if (
                    part_num.lower().strip() in match["ItemName"].lower().strip()
                    or part_num.lower().strip() in match["FrgnName"].lower().strip()
                ):
                    if part_num not in strong_matches:
                        strong_matches[part_num] = []
                    for m in strong_matches[part_num]:
                        if match["ItemCode"] == m["ItemCode"]:
                            break
                    else:
                        strong_matches[part_num].append(match)
                        matched_parts[match["ItemCode"]] = match
                else:
                    if part_num not in weak_matches:
                        weak_matches[part_num] = []
                    for m in weak_matches[part_num]:
                        if m["ItemCode"] == match["ItemCode"]:
                            break
                    else:
                        weak_matches[part_num].append(match)
                        matched_parts[match["ItemCode"]] = match
    with open(str(*output_filepath.split(".")[:-1]) + "_strong.json", "w") as f:
        json.dump(strong_matches, f, indent=4)
    with open(str(*output_filepath.split(".")[:-1]) + "_weak.json", "w") as f:
        json.dump(weak_matches, f, indent=4)


def filter_parts_into_families(input_filepath: str, output_filepath: str):
    with open(input_filepath, "r") as f:
        json_data = json.load(f)
    families: dict[str, dict[str, list]] = {}
    all_parts: set[SAPPart] = set()
    for matches in json_data.values():
        for p in matches:
            part = SAPPart(**p)
            all_parts.add(part)
    for part_num, matches in json_data.items():
        family = part_num.split("-")[0]
        if family not in families:
            families[family] = {
                "matches": [],
                "part_numbers": [],
                "perfect_matches": [],
            }
        for part in all_parts:
            if not any((family in part.ItemName, family in part.FrgnName)):
                continue
            if any((part_num in part.ItemName, part_num in part.FrgnName)):
                families[family]["perfect_matches"].append((part_num, part))
                continue
            if part not in families[family]["matches"]:
                families[family]["matches"].append(part)
            families[family]["part_numbers"].append(part_num)
    with open(output_filepath, "w") as f:
        for k, v in families.items():
            v["matches"] = [part.to_json() for part in v["matches"]]
            v["perfect_matches"] = [
                (part_num, part.to_json()) for part_num, part in v["perfect_matches"]
            ]
        json.dump(families, f, indent=4)


def get_perfect_matches(input_filepath: str, output_filepath: str):
    with open(input_filepath, "r") as f:
        data: dict = json.load(f)
    perfect_matches: set[tuple[int, SAPPart]] = set()
    for family, family_data in data.items():
        for part_num, part_data in family_data["perfect_matches"]:
            perfect_matches.add((part_num, SAPPart(**part_data)))

    print(f"Writing {len(perfect_matches)} perfect matches to {output_filepath}")
    with open(output_filepath, "w") as f:
        json.dump({pn: m.__dict__ for pn, m in perfect_matches}, f, indent=4)


def update_dataframe_with_matches(
    matches: dict[str, dict[str, str]], dataframe: pd.DataFrame
):
    """Updates the dataframe with matches

    Args:
        matches (dict[str, dict[str, str]]): Matches from the file generated by get_perfect_matches
        dataframe (pd.DataFrame): dataframe from eplan spreadsheet
    """
    sap_parts = {pn: SAPPart(**match) for pn, match in matches.items()}
    column_map = map_columns_to_enum(dataframe.values[0])
    for row in dataframe.values[1:]:
        if row[column_map[PartHeader.Type_number]] in matches:
            logging.debug(f"Updating row {row[column_map[PartHeader.Type_number]]}")
            match = sap_parts[row[column_map[PartHeader.Type_number]]].to_eplan_record()
            for header, val in match.items():
                logging.debug(f"Updating {header} with {val}")
                row[column_map[header]] = val


def filter_parts_from_api(input_filepath: str, output_filepath: str):
    if not os.path.isfile(input_filepath):
        raise FileNotFoundError(f"File {input_filepath} not found")
    with open(input_filepath, "r") as f:
        data = json.load(f)
    sorted_data: dict[str, dict[str, list]] = {}
    for part_num, matches in data.items():
        if part_num in sorted_data:
            print(f"WARNING: Part number {part_num} already in sorted data")
        else:
            sorted_data[part_num] = {"strong_match": [], "weak_match": []}
        for match in matches:
            if part_num in match["ItemName"]:
                sorted_data[part_num]["strong_match"].append(match)
            elif part_num in match["FrgnName"]:
                sorted_data[part_num]["strong_match"].append(match)
            else:
                sorted_data[part_num]["weak_match"].append(match)

    with open(output_filepath, "w") as f:
        json.dump(sorted_data, f, indent=4)


def get_parts_from_api(
    df: pd.DataFrame,
    column_map: dict[PartHeader, int],
    query_column: PartHeader = PartHeader.Type_number,
    query_fn: Callable[[str], str] = lambda x: str(x).split("-")[0],
):
    api_controller = APIController()
    results: dict[str, Any] = {}
    for row in df.values[1:]:
        if not (query := row[column_map[query_column]]):
            continue
        query = query_fn(query)
        if query in results:
            continue
        results[query] = []
        try:
            response = api_controller.get_parts(query)
        except ConnectionError as er:
            raise ConnectionError("Error connecting to API") from er
        results[query] = response
    return results


def map_columns_to_enum(columns: pd.Series) -> dict[PartHeader, int]:
    """Searches for each enum in column names and maps the column index to the enum value

    Args:
        df (pd.DataFrame): Dataframe to map

    Returns:
        dict[PartHeader, int]: Dictionary with enum as key and column index as value
    """
    result = {}
    for enum in PartHeader:
        for i, col in enumerate(columns):
            if enum.value == col:
                result[enum] = i
                break
        else:
            raise IndexError(f"Could not find {enum} in {columns}")
    return result


if __name__ == "__main__":
    main()
